# show-me-the-data-structures
Udacity Data Structures Project
6 Different Problems that Explore Data Structures

#Problem 1 #Initial Cache and Linked List Structure - Credit to Udacity #Linked List data structure append: O(1) time #Time Complexity - Cache get uses dictionary data structure to allow access in O(1) time #Time Complexity - Cache set uses dictionary structure to allow access in O(1) time #Space Complexity is O(n) - dictionary size grows in proportion to input

#Problem 2 #Recursively finds filenames in each subfolder to ensure all folders are checked #n input refers to how many files are in the provided directory path #recursion terminates when the last file in the last searched subfolder has been added to the array #Time Complexity is O(n * m)): #searchs through list in provided directory; for each directory, adds n files to list #For each subdirectory - runs m times for each level #list array grows in for loop depending on size of input and depth of directories #Space Complexity is O(n * m): #Starts with base provided directory; for each directory, adds n files to list #For each subdirectory, stores m levels in memory #list array grows in for loop depending on size of input and depth of directories #n is the number of root directories #m is the depth level of the directories

#Problem 3 #Credit to Udacity for base Node, Tree, Stack, and State Structures #Time Complexity - create_tree loops through input in O(n^2) time - min function adds additional O(n) #Time Complexity - huffman_encoding loops through tree in O(n) time #pre_order/traverse appends value to list in o(1) time #encode_string loops through string characters in 0(n) time #Time Complexity - huffman_decoding loops O(n^2) #Creates dictionary with huffman encoded values, deletes numbers #Decodes array of provided binary values and decodes them with provided dictionary #Space Complexity of huffman_encoding is O(n) - visit_order, keys_to_delete grows based on size of linked list #Space Complexity of huffman_decoding/encode_string - O(n) - string grows based on size of input #Space Complexity of create_tree is O(n) - nodes_to_add grows with input

#Problem 4 #Credit to Udacity for base Group and User object #Checks if user is in group or any subgroups by looping through subgroups and recursively calling function so every subgroup is searched #Time Complexity is O(n * m): #Begins with searching list of users in provided group - number of users is n #Searches all potential subgroups recursively - number of levels is m #returns True if user is found at any point #Space complexity is O(n * m) #Top level group is added to memory stack - n #Number of subsequent groups are added to memory stack as needed - m #exits when user is found in any of these groups

#Problem 5 #Credit to Udacity for base Block and LinkedList objects #Block references previous block and previous hash so that it can check whether or not the data has been changed #Time Complexity - Append is O(n) time - loops through linked list once #Space Complexity - Append is O(n) - dependent on size of linked_list #Time Complexity - to_list is O(n) time #Space Complexity is O(1) - to_list no incremental variable growth dependent on input

#Problem 6 #Credit to Udacity for Node and LinkedList data structures #Creates combined list from all values in input lists to create union #Creates intersection list from all values in both input lists to create intersection #Time Complexity- union loops through values of both lists - O(n^2) #Space Complexity - union at worst holds all values from both lists - O(n) #Time Complexity - intersection loops through values of both lists - O(n^2) #Space complexity intersection is O(n) - list grows to greatest maximum if all of one list
